{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Present output data dependent on previous output data\n",
    "and sequence of outputs keep getting repeated many times"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Inputs and outputs are similar\n",
    "ex: current bill data \n",
    "To predict my current bill data, previous bill data is important(here we can use regression too but in regression o/p is dependent on other independent i/p data. whereas in rnn, o/p dependent on previous i/p's only and not on any other data)\n",
    "\n",
    "Stock Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN is feedback network\n",
    "        _________\n",
    "        |       |\n",
    "i/p-----|       |------------------- o/p\n",
    "        |_______|        |\n",
    "            |____________|    "
   ]
  },
  {
   "source": [
    "h(t) = gh(wi*x(t) + wr*h(t-1) + bh)\n",
    "\n",
    "y(t) = gy(wy*h(t) + by)\n",
    "\n",
    "if anywhere h(-ve values) is neglected"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Weights updation: (in any neural net)\n",
    "\n",
    "w(new) = w(old) - dw\n",
    "\n",
    "dw = n*(de/dw)\n",
    "\n",
    "e = (actual output - model output)^2\n",
    "\n",
    "Problem with feedback nets:\n",
    "\n",
    "if i/p doesn't match o/p, weights need to be updated and they keep on decreasing, then(why possibly we need not do fw/bw propagation)\n",
    "\n",
    "if de/dw << 1 then dw <<<<1 (weights reach almost zero)\n",
    "\n",
    "This problem is called vanishing gradient descent(w(new) less than 1 and nearer to zero)\n",
    "\n",
    "sometimes w(new) can be greater than 1, then it's called exploding gradient descent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To overcome we use LSTM(Long Short Term Memory) instead of ANN - Holds Long memories for shorter terms\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "            LSTM STRUCTURE\n",
    "\n",
    "\n",
    "            _____________________________________________\n",
    "___         |   ___                   ___                |      ___\n",
    "|_|---------|-- |x|-------------------|+|----------------|------|_| c(t)\n",
    "c(t-1)      |    |          Cell State |   ______        |      ___\n",
    "            |    |                     |   |tanh|--------|------|_| h(t)\n",
    "            |    |Forget gate i/p gate_|_   _|_          |\n",
    "            |    |              |-----|x|   |x| o/p gate |\n",
    "            |   _|_     ___   __|__         _|_          |\n",
    "            |   |σ|     |σ|   |tanh|        |σ|          |\n",
    "___         |    |       |      |            |           |\n",
    "|_|---------|----|-------|------|------------|           |\n",
    "h(t-1)   |  |____|_______________________________________|\n",
    "        _|_\n",
    "        |_|\n",
    "        xt\n",
    " \n",
    "σ - sigma\n",
    "x - and (point wise multiplication)\n",
    "+ - or  (point wise addition)\n",
    "arrows joining one box to common line is vector concatenation\n",
    "Previous info stored in each cell state"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forget layer:\n",
    "\n",
    "1st σ layer:\n",
    "\n",
    "Identify info not required and will be thrown away from cell state\n",
    "\n",
    "ft = σ(wf[h(t-1),xt] + bf)(remember in sigmoid > 0.5, that info is considered, others are ommitted)\n",
    "\n",
    "2nd σ layer:\n",
    "will decide which values will be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}