{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Steps:\n",
    "\n",
    "initialize model - sequential(ANN)\n",
    "\n",
    "add 2d conv layer - i/p: **(size of image)image,(no of feature detectors - depends on size of image)feature detectors, size of feature detector(nxn - 3,5,7), activation function: reLU, strides(left or right and no of steps)\n",
    "\n",
    "add max pool layer - output of conv layer which is feature map sent to this layer, size of max pool layer, activation function: reLU(default)\n",
    "\n",
    "add flatten layer - output of max pool layer which is feature map sent to this layer\n",
    "\n",
    "add hidden layer of ANN - i/p dim, activation func, weight initialisation\n",
    "\n",
    "add o/p layer of CNN - activation func = softmax, sigmoid, binary step(depends on classification), o/p dim: (depends on classes), weight initialisation\n",
    "\n",
    "image dataset is preprocessed - splitting shud be done manually(annotating, diff images in diff folders) 20%-test_set\n",
    "\n",
    "compile the model - optimizer = sgd,adam, **loss = bin cross entropy, categorical cross entropy, **metrics = [\"accuracy\"]\n",
    "\n",
    "training and testing - **epochs, batch_size\n",
    "\n",
    "save model\n",
    "\n",
    "** - important"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3,3),input_shape = (64,64,3),activation=\"relu\")) #Convolution2D(no_of_feature_detector,size_of_feature_detector(nxn),input_shape(64,64,3)(pixel_size=(64,64) - can also be img szie or img resized for given size(128,512),3(no of channels = 3 for rgb, 2 for W/B, 1 for binary)))\n",
    "#default stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())#activation=\"relu\"(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 128, kernel_initializer=\"uniform\",activation=\"relu\"))#here units for hidden layer is random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 1, kernel_initializer=\"uniform\",activation=\"sigmoid\"))#2powers is used for easy cpu, gpu calculations(memory management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#for Data Augmentation - for single image we generate further images like flip, mirror img, zoom, tilt etc. Keep in mind the data will be not saved. only during the program and training data augmented is used and stored. New data = old data + data augmented\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)#(rescale similar to scalar (normalization)(previously), shear_range, zooming, flip)\n",
    "test_datagen = ImageDataGenerator(rescale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 8005 images belonging to 2 classes.\nFound 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r\"Cats_Dogs\\training_set\",target_size=(64,64),batch_size=32,class_mode=\"binary\")#targetsize is same as that of conv layer, class_mode is no of classes. since 2 classes its binary. if more classes then categorical\n",
    "#batch_size is detrmined by no of images in dataset. if>10000 its 64, 128 and so on. if < 10000 its 32.\n",
    "x_test = test_datagen.flow_from_directory(r\"Cats_Dogs\\test_set\",target_size=(64,64),batch_size=32,class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices) #indices are based on alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 74s 297ms/step - loss: 0.6667 - accuracy: 0.5818 - val_loss: 72.2238 - val_accuracy: 0.6081\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.5970 - accuracy: 0.6809 - val_loss: 135.1534 - val_accuracy: 0.6062\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.5692 - accuracy: 0.7039 - val_loss: 105.9643 - val_accuracy: 0.6300\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.5511 - accuracy: 0.7124 - val_loss: 68.0504 - val_accuracy: 0.7054\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.5261 - accuracy: 0.7310 - val_loss: 146.2968 - val_accuracy: 0.6503\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 22s 88ms/step - loss: 0.5125 - accuracy: 0.7397 - val_loss: 130.1726 - val_accuracy: 0.6314\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.4889 - accuracy: 0.7623 - val_loss: 126.4483 - val_accuracy: 0.6250\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.4831 - accuracy: 0.7653 - val_loss: 147.2695 - val_accuracy: 0.6007\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.4615 - accuracy: 0.7789 - val_loss: 127.4780 - val_accuracy: 0.6533\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.4386 - accuracy: 0.7908 - val_loss: 203.9317 - val_accuracy: 0.6032\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1855740ce80>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=250,epochs=10,validation_data=x_test,validation_steps=63)\n",
    "#steps_per_epoch = no of training images/batch_size\n",
    "#validation_steps = no of testing images/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = load_model(\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r\"cat_test_image.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = save_model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "pred"
   ]
  }
 ]
}